program: train.py
method: random  # or grid, random, bayes
metric:
  name: val_loss
  goal: minimize
parameters:
  fast_run:
    values: [True] # use special a100 setting for torch.set_float32_matmul_precision("high")
  use_sweep:
    values: [True]
  config: 
    values: [configs/captioning/webvid_small.yaml] # This is the base config file to use
  lr:
    values: [1e-3, 2e-3, 4e-3, 1e-4]
  num_frames:
    values: [16]
  head:
    values: [linear]
  head_dropout:
    min: 0.0
    max: 0.7
  head_weight_decay:
    values: [0.0, 0.05, 0.1]
  backbone_weight_decay:
    values: [0.0, 0.05, 0.1]
  prompt_weight_decay:
    values: [0.0, 0.05, 0.1]
  prompt_lr_multiplier:
    values: [0.0001, 0.01, 0.2, 1.0]
  num_frozen_epochs:
    values: [0, 1]
  max_epochs:
    values: [4] 
  backbone_lr_multiplier:
    values: [0.0001, 0.01, 0.2, 1.0]
  text_decoder_lr_multiplier:
    values: [0.0001, 0.01, 0.2, 1.0]
  text_first:
    values: [True, False]
  use_start_token_for_caption:
    values: [True, False]
  num_learnable_prompt_tokens:
    values: [0, 1, 2, 4, 8, 16]
  prompt:
    values: ["A photo of a ", "A video of a ", "A video of a person ", "A video of a person doing ", "A video of a person doing a "]
  # Add other parameters you want to tune
