# This is not currently used, but it is how I will configure the codebase
# TODO: Load with OmegaConf from default.yaml
data:
  datasets: 
    - 500p_new0 # contains the re-annotated videos in training split
  num_frames: 16

model:
  type: dual_encoder # which module to use
  backbone_name: clip_ViT-B/32
  text_encoder_name: clip_ViT-B/32
  head: null
  shared_embed_dim: null # Detect from backbone
  head_dropout: 0.0
  head_weight_decay: 0.0
  backbone_weight_decay: 0.0

trainer:
  lr: 1e-5
  batch_size: 16
  max_epochs: 10
  num_frozen_epochs: 0
  backbone_lr_multiplier: 1.0
  text_encoder_lr_multiplier: 1.0
  precision: 32
  drop_repeat_text: True
  num_workers: cpus-4

logger:
  log_every_n_steps: 10
